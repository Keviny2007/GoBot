{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b668656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlgo.data.parallel_processor import GoDataProcessor\n",
    "from dlgo.encoders.simple import SimpleEncoder\n",
    "from layers import layers\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dec50a",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_size = 19\n",
    "num_classes = board_size * board_size\n",
    "num_games = 100\n",
    "\n",
    "encoder = SimpleEncoder((board_size, board_size))\n",
    "\n",
    "processor = GoDataProcessor(encoder=encoder.name(), data_directory='data')\n",
    "\n",
    "generator = processor.load_go_data('train', num_games, use_generator=True)\n",
    "test_generator = processor.load_go_data('test', num_games, use_generator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoDatasetWrapper(Dataset):\n",
    "    def __init__(self, generator, batch_size, num_classes):\n",
    "        self.generator = generator.generate(batch_size, num_classes)\n",
    "        self.num_samples = generator.get_num_samples()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # one batch\n",
    "        X, y = next(self.generator)\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.long)  # class indices for CrossEntropyLoss\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8024e3f7",
   "metadata": {},
   "source": [
    "Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe04811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterGoCNN(nn.Module):\n",
    "    def __init__(self, board_size=19):\n",
    "        super(BetterGoCNN, self).__init__()\n",
    "        input_shape = (11, board_size, board_size)\n",
    "\n",
    "        self.model = layers(input_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d28dc9",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a02d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BetterGoCNN(board_size)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "train_dataset = GoDatasetWrapper(generator, batch_size=128, num_classes=num_classes)\n",
    "test_dataset = GoDatasetWrapper(test_generator, batch_size=128, num_classes=num_classes)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d912f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        inputs, targets = inputs.squeeze(0).to(device), targets.squeeze(0).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Train Loss: {running_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"small_model_epoch_{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be58ed3",
   "metadata": {},
   "source": [
    "Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e942a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "eval_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.squeeze(0).to(device), targets.squeeze(0).to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        eval_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "print(f\"Test Loss: {eval_loss:.4f}, Accuracy: {correct/total:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
