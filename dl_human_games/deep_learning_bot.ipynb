{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b668656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlgo.data.parallel_processor import GoDataProcessor\n",
    "from dlgo.encoders.simple import SimpleEncoder\n",
    "from layers import layers\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dec50a",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e827d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "print(glob.glob('GoBot/data/*_features_*.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e58cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if .npy files already exist\n",
    "def colab_safe_map_to_workers(self, data_type, samples):\n",
    "    print(\">> [Colab] Skipping map_to_workers to avoid multiprocessing.\")\n",
    "    return\n",
    "\n",
    "GoDataProcessor.map_to_workers = colab_safe_map_to_workers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_size = 19\n",
    "num_classes = board_size * board_size\n",
    "num_games = 100\n",
    "\n",
    "encoder = SimpleEncoder((board_size, board_size))\n",
    "\n",
    "processor = GoDataProcessor(encoder=encoder.name(), data_directory='data')\n",
    "\n",
    "generator = processor.load_go_data('train', num_games, use_generator=True)\n",
    "test_generator = processor.load_go_data('test', num_games, use_generator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f917238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(generator.generate(batch_size=128))\n",
    "print(x_batch.shape, y_batch.shape)\n",
    "x_batch, y_batch = next(test_generator.generate(batch_size=128))\n",
    "print(x_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoDatasetWrapper(Dataset):\n",
    "    def __init__(self, generator, batch_size, num_classes):\n",
    "        self.generator = generator.generate(batch_size, num_classes)\n",
    "        self.num_samples = generator.get_num_samples()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # one batch\n",
    "        X, y = next(self.generator)\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.long)  # class indices for CrossEntropyLoss\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8024e3f7",
   "metadata": {},
   "source": [
    "Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe04811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterGoCNN(nn.Module):\n",
    "    def __init__(self, board_size=19):\n",
    "        super(BetterGoCNN, self).__init__()\n",
    "        input_shape = (11, board_size, board_size)\n",
    "\n",
    "        self.model = layers(input_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d28dc9",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a02d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BetterGoCNN(board_size)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "train_dataset = GoDatasetWrapper(generator, batch_size=128, num_classes=num_classes)\n",
    "test_dataset = GoDatasetWrapper(test_generator, batch_size=128, num_classes=num_classes)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5158f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train loader has {len(train_loader)} batches\")\n",
    "print(f\"Test loader has {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d912f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        targets = targets.argmax(dim=1)  # convert one-hot to class index\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_correct += (predicted == targets).sum().item()\n",
    "        train_total += targets.size(0)\n",
    "\n",
    "    train_accuracy = train_correct / train_total\n",
    "\n",
    "    # === Validation phase ===\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=f\"Validation Epoch {epoch+1}\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets.argmax(dim=1)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == targets).sum().item()\n",
    "            val_total += targets.size(0)\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"small_model_epoch_{epoch+1}.pth\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
